# -*- coding: utf-8 -*-
"""Traffic-Sign-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/199v0JqZCRzGT8B4McFDwi5t_50I9PiiI

Download dataset from here https://www.kaggle.com/valentynsichkar/traffic-signs-preprocessed
"""

import os
import pickle
import zipfile
import pandas as pd
import tensorflow as tf
from keras.utils.np_utils import to_categorical

zip_ref = zipfile.ZipFile('/content/data2.pickle.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

# Opening file for reading in binary mode
with open('/content/data2.pickle', 'rb') as f:
    data = pickle.load(f, encoding='latin1')  # dictionary type

# Preparing y_train and y_validation for using in Keras
data['y_train'] = to_categorical(data['y_train'], num_classes=43)
data['y_validation'] = to_categorical(data['y_validation'], num_classes=43)

# Making channels come at the end
data['x_train'] = data['x_train'].transpose(0, 2, 3, 1)
data['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)
data['x_test'] = data['x_test'].transpose(0, 2, 3, 1)

# Showing loaded data from file
for i, j in data.items():
    if i == 'labels':
        print(i + ':', len(j))
    else: 
        print(i + ':', j.shape)

# Create sequential model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, kernel_size=15, activation='relu',input_shape=(32, 32, 3)),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Flatten(), 
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.125),
    tf.keras.layers.Dense(43, activation='softmax')  
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Make callback function for reducing learning rate
def scheduler(epoch, lr):
    return lr * tf.math.exp(-0.1)

learningRate = tf.keras.callbacks.LearningRateScheduler(
    scheduler, verbose=0
)


#Training Model
history = model.fit(data['x_train'], data['y_train'],
                    batch_size=5, epochs = 10,
                    validation_data = (data['x_validation'], data['y_validation']),
                    callbacks=[learningRate]
                    )

# Defining function for getting texts for every class - labels
def label_text(file):
    # Defining list for saving label in order from 0 to 42
    label_list = []
    
    # Reading 'csv' file and getting image's labels
    r = pd.read_csv(file)
    # Going through all names
    for name in r['SignName']:
        # Adding from every row second column with name of the label
        label_list.append(name)
    
    # Returning resulted list with labels
    return label_list


# Getting labels
labels = label_text('/content/label_names.csv')

# Code for predicting image
import matplotlib.pyplot as plt
import numpy as np
from keras.preprocessing import image
from google.colab import files

uploaded = files.upload()
for fn in uploaded.keys():
  path = fn
  img_source = image.load_img(path, target_size = (32, 32))
  plt.imshow(img_source)
  x = image.img_to_array(img_source)
  x = np.expand_dims(x, axis = 0)

hasil = model.predict(x)

# Scores is given for image with 43 numbers of predictions for each class
# Getting only one class with maximum value
nama = np.argmax(hasil)
print('ClassId:', nama)
print('Label:', labels[nama])

#Save model
model.save('model_final.h5')