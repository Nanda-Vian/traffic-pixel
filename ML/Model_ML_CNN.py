# -*- coding: utf-8 -*-
"""capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HBrPpsaGTBtvfCTLGgcLf81RT3tYiwKj
"""

"""#Model Kedua"""
import keras
import numpy as np 
import pandas as pd 
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator
from keras.layers import Dense, Flatten,BatchNormalization, Dropout, Lambda, Conv2D, MaxPool2D
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Flatten,BatchNormalization, Dropout, Lambda

data = pd.read_pickle("/content/Dataset/data8.pickle")

print("x train shape:", data["x_train"].shape)
print("y train shape:", data["y_train"].shape)
print("x test shape:", data["x_test"].shape)
print("y test shape:", data["y_test"].shape)
print("x validation shape:", data["x_validation"].shape)
print("y validation shape:", data["y_validation"].shape)

x_train = data["x_train"]
x_test = data["x_test"]
x_val = data["x_validation"]
y_train = data["y_train"]
y_val = data["y_validation"]

x_train = x_train.swapaxes(1,2)
x_train = x_train.swapaxes(2,3)

x_train.shape

x_val = x_val.swapaxes(1,2)
x_val = x_val.swapaxes(2,3)
print("x val shape:", x_val.shape)

plt.imshow(x_train[2][:,:,0],cmap='gray')
plt.show()

NumberofClass = 43
y_train = to_categorical(y_train, num_classes = NumberofClass)
y_val = to_categorical(y_val, num_classes = NumberofClass)

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # dimesion reduction
        rotation_range=5,  # randomly rotate images in the range 5 degrees
        zoom_range = 0.1, # Randomly zoom image 10%  0,1 best
        width_shift_range=0.1,  # randomly shift images horizontally 10%  +++
        height_shift_range=0.1,  # randomly shift images vertically 10%
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images

datagen.fit(x_train)

model = Sequential()

model.add(Conv2D(filters = 128, kernel_size = (4,4), padding = "Same", activation = "relu", input_shape = (32,32,1)))

model.add(MaxPool2D(pool_size = (2,2)))

model.add(Conv2D(filters = 64, kernel_size = (4,4), padding = "Same", activation = "relu" ))

model.add(MaxPool2D(pool_size = (2,2)))

model.add(Conv2D(filters = 32, kernel_size = (4,4), padding = "Same", activation = "relu" ))

model.add(MaxPool2D(pool_size = (2,2)))

model.add(Conv2D(filters = 16, kernel_size = (4,4), padding = "Same", activation = "relu" ))

model.add(MaxPool2D(pool_size = (2,2)))

model.add(Flatten())

model.add(Dense(units = 512, activation = "relu"))

model.add(Dropout(0.5))

model.add(Dense(units = NumberofClass, activation = "softmax"))

model.compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = ["accuracy"])

model.summary()

history = model.fit(datagen.flow(x_train,y_train, batch_size=250),
                              epochs = 10, validation_data = (x_val,y_val))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# Preparing image for predicting from test dataset
x_input = data['x_test'][99:100]
x_input = x_input.swapaxes(1,2)
x_input = x_input.swapaxes(2,3)
print(x_input.shape)
y_input = data['y_test'][99:100]
print(y_input)

model.save('model_kedua.h5')

scores = model.predict(x_input)

# Scores is given for image with 43 numbers of predictions for each class
# Getting only one class with maximum value
prediction = np.argmax(scores)
print('ClassId:', prediction)

def label_text(file):
    # Defining list for saving label in order from 0 to 42
    label_list = []
    
    # Reading 'csv' file and getting image's labels
    r = pd.read_csv(file)
    # Going through all names
    for name in r['SignName']:
        # Adding from every row second column with name of the label
        label_list.append(name)
    
    # Returning resulted list with labels
    return label_list


# Getting labels
labels = label_text('/content/Dataset/label_names.csv')

# Printing label for classified Traffic Sign
print('Label:', labels[prediction])

from google.colab import files
uploaded = files.upload()

from keras.preprocessing import image

for fn in uploaded.keys():
  path = fn
  img_source = image.load_img(path, target_size = (32, 32))
  plt.imshow(img_source)

  img_gray = image.load_img(path, target_size=(32,32), color_mode='grayscale')
  x = image.img_to_array(img_gray)
  x = np.expand_dims(x, axis = 0)

hasil = model.predict(x)

# Scores is given for image with 43 numbers of predictions for each class
# Getting only one class with maximum value
nama = np.argmax(hasil)
print('ClassId:', nama)
print('Label:', labels[nama])